{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6cab95",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238fc53c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import ecdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74255039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f6c87",
   "metadata": {},
   "source": [
    "# The arguments that we pass in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4533b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myargs():\n",
    "    def __init__(self):\n",
    "        self.exp_id = 'efficientnet_round1'\n",
    "        self.epochs = 200\n",
    "        self.model = 'efficientnet'\n",
    "        self.model_type = 'b3'\n",
    "        self.image_dims = 256\n",
    "        self.rotation_range = 60\n",
    "        self.width_shift_range = 0.05\n",
    "        self.height_shift_range = 0.05\n",
    "        self.brightness_range = None\n",
    "        self.zoom_range = 0.05\n",
    "        self.horizontal_flip = True\n",
    "        self.vertical_flip = True\n",
    "        self.validation_split = 0.1\n",
    "        self.batch_size = 8\n",
    "        self.class_mode = 'categorical'\n",
    "        \n",
    "# {\n",
    "#     \"exp_id\": \"repeat_experiment_batch_10\",\n",
    "#     \"learning_rate\": 0.0001,\n",
    "#     \"epochs\": 200,\n",
    "#     \"rotation_range\": 60,\n",
    "#     \"width_shift_range\": 0.05,\n",
    "#     \"height_shift_range\": 0.05,\n",
    "#     \"brightness_range\": null,\n",
    "#     \"zoom_range\": 0.05,\n",
    "#     \"horizontal_flip\": true,\n",
    "#     \"vertical_flip\": true,\n",
    "#     \"validation_split\": 0.1,\n",
    "#     \"model\": \"categorical_efficientnet\",\n",
    "#     \"image_dims\": 224,\n",
    "#     \"class_mode\": \"categorical\",\n",
    "#     \"batch_size\": 10\n",
    "# }        \n",
    "\n",
    "args = myargs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e6438",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f2ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 993 images belonging to 2 classes.\n",
      "Found 109 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/workspaces/ecdl/elbow_data/SABINE_Training_Set'\n",
    "\n",
    "base_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=args.rotation_range,\n",
    "                                                                       width_shift_range=args.width_shift_range,\n",
    "                                                                       height_shift_range=args.height_shift_range,\n",
    "                                                                       brightness_range=args.brightness_range,\n",
    "                                                                       zoom_range=args.zoom_range,\n",
    "                                                                       horizontal_flip=args.horizontal_flip,\n",
    "                                                                       vertical_flip=args.vertical_flip,\n",
    "                                                                       rescale=1./255,\n",
    "                                                                       validation_split = args.validation_split)\n",
    "\n",
    "\n",
    "\n",
    "train_data_gen = base_image_generator.flow_from_directory(batch_size=args.batch_size,\n",
    "                                                        target_size=(args.image_dims, args.image_dims),\n",
    "                                                        directory=train_dir,\n",
    "                                                        shuffle=True,\n",
    "                                                        class_mode=args.class_mode,\n",
    "                                                        subset='training')\n",
    "\n",
    "\n",
    "\n",
    "val_data_gen = base_image_generator.flow_from_directory(batch_size=args.batch_size,\n",
    "                                                        target_size=(args.image_dims, args.image_dims),\n",
    "                                                        directory=train_dir,\n",
    "                                                        shuffle=True,\n",
    "                                                        class_mode=args.class_mode,\n",
    "                                                        subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6224b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f379f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 256, 256, 3)\n",
      "(8, 2)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(sample[0].shape)\n",
    "print(sample[1].shape)\n",
    "print(sample[0].shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49f499",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fa22496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (300, 300, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-70e41d2246cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                             \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                             input_shape=sample[0].shape[1:])                                      \n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.compile(optimizer='adam',\n",
      "\u001b[0;32m/workspaces/ecdl/ecdl/models.py\u001b[0m in \u001b[0;36mtensorflow_efficientnet\u001b[0;34m(model_name, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel_builder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetB4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mefficientnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/efficientnet.py\u001b[0m in \u001b[0;36mEfficientNetB3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0mclassifier_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_activation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/efficientnet.py\u001b[0m in \u001b[0;36mEfficientNet\u001b[0;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       weights=weights)\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    343\u001b[0m         raise ValueError('When setting `include_top=True` '\n\u001b[1;32m    344\u001b[0m                          \u001b[0;34m'and loading `imagenet` weights, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                          '`input_shape` should be ' + str(default_shape) + '.')\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (300, 300, 3)."
     ]
    }
   ],
   "source": [
    "model = ecdl.models.tensorflow_efficientnet(model_name=args.model_type,\n",
    "#                                             classes=2,\n",
    "                                            weights='imagenet',\n",
    "                                            include_top=True,\n",
    "                                            input_shape=sample[0].shape[1:])                                      \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c438e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 256, 256, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 257, 257, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 128, 128, 40) 1080        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 128, 128, 40) 160         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 128, 128, 40) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 128, 128, 40) 360         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 128, 128, 40) 160         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 128, 128, 40) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 40)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 40)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 10)     410         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 40)     440         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 128, 128, 40) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 128, 128, 24) 960         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 128, 128, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 128, 128, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 128, 128, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 128, 128, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 128, 128, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 128, 128, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 128, 128, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 128, 128, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 128, 128, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 128, 128, 144 3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 128, 128, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 128, 128, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 129, 129, 144 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 64, 64, 144)  1296        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 64, 64, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 64, 64, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 64, 64, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 64, 64, 32)   4608        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 64, 64, 32)   128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 64, 64, 192)  6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 64, 64, 192)  768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 64, 64, 192)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 64, 64, 192)  1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 64, 64, 192)  768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 64, 64, 192)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 64, 64, 192)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 64, 64, 32)   6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 64, 64, 32)   128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 64, 64, 32)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 64, 64, 32)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 64, 64, 192)  6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 64, 64, 192)  768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 64, 64, 192)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 64, 64, 192)  1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 64, 64, 192)  768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 64, 64, 192)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 64, 64, 192)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 64, 64, 32)   6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 64, 64, 32)   128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 64, 64, 32)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 64, 64, 32)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 64, 64, 192)  6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 64, 64, 192)  768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 64, 64, 192)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 67, 67, 192)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 32, 32, 192)  4800        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 32, 32, 192)  768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 32, 32, 192)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 32, 32, 192)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 32, 32, 48)   9216        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 32, 32, 48)   192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 32, 32, 288)  13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 32, 32, 288)  1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 32, 32, 288)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 32, 32, 288)  7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 32, 32, 288)  1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 32, 32, 288)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 32, 32, 288)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 32, 32, 48)   13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 32, 32, 48)   192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 32, 32, 48)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 32, 32, 48)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 32, 32, 288)  13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 32, 32, 288)  1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 32, 32, 288)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 32, 32, 288)  7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 32, 32, 288)  1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 32, 32, 288)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 32, 32, 288)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 32, 32, 48)   13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 32, 32, 48)   192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 32, 32, 48)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 32, 32, 48)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 32, 32, 288)  13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 32, 32, 288)  1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 32, 32, 288)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 33, 33, 288)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 16, 16, 288)  2592        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 16, 16, 288)  1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 16, 16, 288)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 16, 16, 288)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 16, 16, 96)   27648       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 16, 16, 96)   384         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 16, 16, 576)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 16, 16, 576)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 576)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 16, 16, 576)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 16, 16, 96)   384         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 16, 16, 96)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 16, 16, 96)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 16, 16, 576)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 16, 16, 576)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 576)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 16, 16, 576)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 16, 16, 96)   384         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 16, 16, 96)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 16, 16, 96)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 16, 16, 576)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 16, 16, 576)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 576)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 16, 16, 576)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 16, 16, 96)   384         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 16, 16, 96)   0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 16, 16, 96)   0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 16, 16, 576)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 16, 16, 576)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 576)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 16, 16, 576)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 16, 16, 96)   384         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 16, 16, 96)   0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 16, 16, 96)   0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 16, 16, 576)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 16, 16, 576)  14400       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 16, 16, 576)  2304        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 16, 16, 576)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 576)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 576)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 16, 16, 576)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 16, 16, 136)  78336       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 16, 16, 136)  544         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 16, 16, 816)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 16, 16, 816)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 816)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 16, 16, 816)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 16, 16, 136)  544         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 16, 16, 136)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 16, 16, 136)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 16, 16, 816)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 16, 16, 816)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 816)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 16, 16, 816)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 16, 16, 136)  544         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 16, 16, 136)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 16, 16, 136)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 16, 16, 816)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 16, 16, 816)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 816)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 16, 16, 816)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 16, 16, 136)  544         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 16, 16, 136)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 16, 16, 136)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 16, 16, 816)  0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 16, 16, 816)  0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 816)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 16, 16, 816)  0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 16, 16, 136)  544         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 16, 16, 136)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 16, 16, 136)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 16, 16, 816)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 19, 19, 816)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 8, 8, 816)    20400       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 8, 8, 816)    3264        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 8, 8, 816)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 816)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 816)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 8, 8, 816)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 8, 8, 232)    189312      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 8, 8, 232)    928         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 8, 8, 1392)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 8, 8, 1392)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1392)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 8, 8, 232)    928         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 8, 8, 232)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 8, 8, 232)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 8, 8, 1392)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 8, 8, 1392)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1392)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 8, 8, 232)    928         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 8, 8, 232)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 8, 8, 232)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 8, 8, 1392)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 8, 8, 1392)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1392)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 8, 8, 232)    928         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 8, 8, 232)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 8, 8, 232)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 8, 8, 1392)   0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 8, 8, 1392)   0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1392)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 8, 8, 232)    928         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 8, 8, 232)    0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 8, 8, 232)    0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 8, 8, 1392)   0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 8, 8, 1392)   0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1392)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 8, 8, 232)    928         block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 8, 8, 232)    0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 8, 8, 232)    0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 8, 8, 1392)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   12528       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 8, 8, 1392)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1392)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 8, 8, 1392)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 8, 8, 384)    534528      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 8, 8, 384)    1536        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 8, 8, 2304)   884736      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 8, 8, 2304)   9216        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 8, 8, 2304)   0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 8, 8, 2304)   20736       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 8, 8, 2304)   9216        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 8, 8, 2304)   0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2304)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 8, 8, 2304)   0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 8, 8, 384)    884736      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 8, 8, 384)    1536        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 8, 8, 384)    0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 8, 8, 384)    0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 8, 8, 1536)   589824      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 8, 8, 1536)   6144        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 8, 8, 1536)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1536)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 2)            3074        top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 10,786,609\n",
      "Trainable params: 10,699,306\n",
      "Non-trainable params: 87,303\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base = ecdl.models.tensorflow_efficientnet(model_name=args.model_type,                                                 \n",
    "                                                 weights='imagenet',\n",
    "                                                 include_top=False,\n",
    "                                                 input_shape=sample[0].shape[1:])                                      \n",
    "\n",
    "# model_base.trainable = False\n",
    "\n",
    "# Rebuild top\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model_base.output)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.2\n",
    "x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Compile\n",
    "model = tf.keras.Model(model_base.input, outputs, name=\"EfficientNet\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ba0698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 128, 128, 40) 1080        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 128, 128, 40) 160         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 128, 128, 40) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 128, 128, 40) 360         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 128, 128, 40) 160         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 128, 128, 40) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 40)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 40)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 10)     410         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 40)     440         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 128, 128, 40) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 128, 128, 24) 960         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 128, 128, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 128, 128, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 128, 128, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 128, 128, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 128, 128, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 128, 128, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 128, 128, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 128, 128, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 128, 128, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 128, 128, 144 3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 128, 128, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 128, 128, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 64, 64, 144)  1296        block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 64, 64, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 64, 64, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 64, 64, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 64, 64, 32)   4608        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 64, 64, 32)   128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 64, 64, 192)  6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 64, 64, 192)  768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 64, 64, 192)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 64, 64, 192)  1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 64, 64, 192)  768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 64, 64, 192)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 64, 64, 192)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 64, 64, 32)   6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 64, 64, 32)   128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 64, 64, 32)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 64, 64, 32)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 64, 64, 192)  6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 64, 64, 192)  768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 64, 64, 192)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 64, 64, 192)  1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 64, 64, 192)  768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 64, 64, 192)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 64, 64, 192)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 64, 64, 32)   6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 64, 64, 32)   128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 64, 64, 32)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 64, 64, 32)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 64, 64, 192)  6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 64, 64, 192)  768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 64, 64, 192)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 32, 32, 192)  4800        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 32, 32, 192)  768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 32, 32, 192)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 32, 32, 192)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 32, 32, 48)   9216        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 32, 32, 48)   192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 32, 32, 288)  13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 32, 32, 288)  1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 32, 32, 288)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 32, 32, 288)  7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 32, 32, 288)  1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 32, 32, 288)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 32, 32, 288)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 32, 32, 48)   13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 32, 32, 48)   192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 32, 32, 48)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 32, 32, 48)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 32, 32, 288)  13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 32, 32, 288)  1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 32, 32, 288)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 32, 32, 288)  7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 32, 32, 288)  1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 32, 32, 288)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 32, 32, 288)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 32, 32, 48)   13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 32, 32, 48)   192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 32, 32, 48)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 32, 32, 48)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 32, 32, 288)  13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 32, 32, 288)  1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 32, 32, 288)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 16, 16, 288)  2592        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 16, 16, 288)  1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 16, 16, 288)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 16, 16, 288)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 16, 16, 96)   27648       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 16, 16, 96)   384         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 16, 16, 576)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 16, 16, 576)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 576)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 16, 16, 576)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 16, 16, 96)   384         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 16, 16, 96)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 16, 16, 96)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 16, 16, 576)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 16, 16, 576)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 576)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 16, 16, 576)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 16, 16, 96)   384         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 16, 16, 96)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 16, 16, 96)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 16, 16, 576)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 16, 16, 576)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 576)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 16, 16, 576)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 16, 16, 96)   384         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 16, 16, 96)   0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 16, 16, 96)   0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 16, 16, 576)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 16, 16, 576)  5184        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 16, 16, 576)  2304        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 16, 16, 576)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 576)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 16, 16, 576)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 16, 16, 96)   55296       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 16, 16, 96)   384         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (FixedDropout)     (None, 16, 16, 96)   0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 16, 16, 96)   0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 16, 16, 576)  55296       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 16, 16, 576)  2304        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 16, 16, 576)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 16, 16, 576)  14400       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 16, 16, 576)  2304        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 16, 16, 576)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 576)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 576)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 16, 16, 576)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 16, 16, 136)  78336       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 16, 16, 136)  544         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 16, 16, 816)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 16, 16, 816)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 816)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 16, 16, 816)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 16, 16, 136)  544         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 16, 16, 136)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 16, 16, 136)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 16, 16, 816)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 16, 16, 816)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 816)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 16, 16, 816)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 16, 16, 136)  544         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 16, 16, 136)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 16, 16, 136)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 16, 16, 816)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 16, 16, 816)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 816)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 16, 16, 816)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 16, 16, 136)  544         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 16, 16, 136)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 16, 16, 136)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 16, 16, 816)  0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 16, 16, 816)  20400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 16, 16, 816)  3264        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 16, 16, 816)  0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 816)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 16, 16, 816)  0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 16, 16, 136)  110976      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 16, 16, 136)  544         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (FixedDropout)     (None, 16, 16, 136)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 16, 16, 136)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 16, 16, 816)  110976      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 16, 16, 816)  3264        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 16, 16, 816)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 8, 8, 816)    20400       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 8, 8, 816)    3264        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 8, 8, 816)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 816)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 816)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 8, 8, 816)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 8, 8, 232)    189312      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 8, 8, 232)    928         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 8, 8, 1392)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 8, 8, 1392)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1392)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 8, 8, 232)    928         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 8, 8, 232)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 8, 8, 232)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 8, 8, 1392)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 8, 8, 1392)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1392)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 8, 8, 232)    928         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 8, 8, 232)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 8, 8, 232)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 8, 8, 1392)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 8, 8, 1392)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1392)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 8, 8, 232)    928         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 8, 8, 232)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 8, 8, 232)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 8, 8, 1392)   0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 8, 8, 1392)   0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1392)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 8, 8, 232)    928         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 8, 8, 232)    0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 8, 8, 232)    0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 8, 8, 1392)   0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   34800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 8, 8, 1392)   0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1392)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 8, 8, 1392)   0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 8, 8, 232)    322944      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 8, 8, 232)    928         block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (FixedDropout)     (None, 8, 8, 232)    0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 8, 8, 232)    0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 8, 8, 1392)   322944      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 8, 8, 1392)   5568        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 8, 8, 1392)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 8, 8, 1392)   12528       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 8, 8, 1392)   5568        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 8, 8, 1392)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1392)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 8, 8, 1392)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 8, 8, 384)    534528      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 8, 8, 384)    1536        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 8, 8, 2304)   884736      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 8, 8, 2304)   9216        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 8, 8, 2304)   0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 8, 8, 2304)   20736       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 8, 8, 2304)   9216        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 8, 8, 2304)   0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2304)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 8, 8, 2304)   0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 8, 8, 384)    884736      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 8, 8, 384)    1536        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 8, 8, 384)    0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 8, 8, 384)    0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 8, 8, 1536)   589824      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 8, 8, 1536)   6144        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 8, 8, 1536)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1536)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 2)            3074        top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 10,786,602\n",
      "Trainable params: 10,699,306\n",
      "Non-trainable params: 87,296\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from efficientnet.tfkeras import EfficientNetB3\n",
    "\n",
    "efficient_net = EfficientNetB3(\n",
    "        weights='imagenet',\n",
    "        input_shape=(256, 256, 3),\n",
    "        include_top=False,\n",
    "#         pooling='max'\n",
    "    )\n",
    "\n",
    "# Basic\n",
    "# x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"dense_1\")(efficient_net.output)\n",
    "# x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"dense_2\")(x)\n",
    "# outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Rebuild top\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(efficient_net.output)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "top_dropout_rate = 0.2\n",
    "x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "model = tf.keras.Model(efficient_net.input, outputs, name=\"EfficientNet\")\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effa6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 200)     5600      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 252, 252, 180)     324180    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 180)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 180)       291780    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 140)       226940    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 44, 44, 100)       126100    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 42, 42, 50)        45050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 180)               576180    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               18100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 1,619,082\n",
      "Trainable params: 1,619,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as Layers\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Layers.Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(256,256,3)))\n",
    "model.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Layers.MaxPool2D(5,5))\n",
    "model.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Layers.Conv2D(140,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Layers.Conv2D(100,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Layers.Conv2D(50,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Layers.MaxPool2D(5,5))\n",
    "model.add(Layers.Flatten())\n",
    "model.add(Layers.Dense(180,activation='relu'))\n",
    "model.add(Layers.Dense(100,activation='relu'))\n",
    "model.add(Layers.Dense(50,activation='relu'))\n",
    "model.add(Layers.Dropout(rate=0.5))\n",
    "model.add(Layers.Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d37840c",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce00b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = os.path.join('/workspaces/ecdl/experiments', args.exp_id)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(exp_path+'/weights.{epoch}-{val_accuracy:.4f}.hdf5', monitor='val_accuracy', verbose=1,save_best_only=True)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', verbose = 1, patience=50)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(exp_path,'result.csv'))\n",
    "delete_excess = ecdl.callbacks.delete_excess_callback(exp_folder=exp_path)\n",
    "callbacks_list = [checkpoint, earlystopping, csv_logger, delete_excess]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ce09d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e239c8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/125 [..............................] - ETA: 12s - loss: 0.7059 - accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0484s vs `on_train_batch_end` time: 0.1496s). Check your callbacks.\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5468\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55046, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.1-0.5505.hdf5\n",
      "125/125 [==============================] - 28s 223ms/step - loss: 0.6940 - accuracy: 0.5468 - val_loss: 0.6913 - val_accuracy: 0.5505\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.5498\n",
      "Epoch 00002: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 27s 219ms/step - loss: 0.6905 - accuracy: 0.5498 - val_loss: 0.6873 - val_accuracy: 0.5505\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5468\n",
      "Epoch 00003: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.6917 - accuracy: 0.5468 - val_loss: 0.6891 - val_accuracy: 0.5505\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5448\n",
      "Epoch 00004: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 223ms/step - loss: 0.6922 - accuracy: 0.5448 - val_loss: 0.6903 - val_accuracy: 0.5505\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.5478\n",
      "Epoch 00005: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 223ms/step - loss: 0.6913 - accuracy: 0.5478 - val_loss: 0.6899 - val_accuracy: 0.5505\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.5448\n",
      "Epoch 00006: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.6898 - accuracy: 0.5448 - val_loss: 0.6885 - val_accuracy: 0.5505\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6904 - accuracy: 0.5468\n",
      "Epoch 00007: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 29s 228ms/step - loss: 0.6904 - accuracy: 0.5468 - val_loss: 0.6885 - val_accuracy: 0.5505\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.5488\n",
      "Epoch 00008: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 220ms/step - loss: 0.6881 - accuracy: 0.5488 - val_loss: 0.6870 - val_accuracy: 0.5505\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.5458\n",
      "Epoch 00009: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.6893 - accuracy: 0.5458 - val_loss: 0.6835 - val_accuracy: 0.5505\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.5579\n",
      "Epoch 00010: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.6890 - accuracy: 0.5579 - val_loss: 0.6856 - val_accuracy: 0.5505\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.5458\n",
      "Epoch 00011: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 27s 220ms/step - loss: 0.6879 - accuracy: 0.5458 - val_loss: 0.6848 - val_accuracy: 0.5505\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.5428\n",
      "Epoch 00012: val_accuracy did not improve from 0.55046\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.6864 - accuracy: 0.5428 - val_loss: 0.6859 - val_accuracy: 0.5505\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.5468\n",
      "Epoch 00013: val_accuracy improved from 0.55046 to 0.58716, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.13-0.5872.hdf5\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.6833 - accuracy: 0.5468 - val_loss: 0.6862 - val_accuracy: 0.5872\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.5509\n",
      "Epoch 00014: val_accuracy did not improve from 0.58716\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.6789 - accuracy: 0.5509 - val_loss: 0.6823 - val_accuracy: 0.5505\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5468\n",
      "Epoch 00015: val_accuracy did not improve from 0.58716\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.6918 - accuracy: 0.5468 - val_loss: 0.6863 - val_accuracy: 0.5505\n",
      "Epoch 16/200\n",
      " 90/125 [====================>.........] - ETA: 7s - loss: 0.6924 - accuracy: 0.5330"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c35fa4e6aafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_data_gen,\n",
    "        epochs = args.epochs,\n",
    "        steps_per_epoch = len(train_data_gen),        \n",
    "        validation_data = val_data_gen,\n",
    "        verbose = 1,\n",
    "        validation_steps = len(val_data_gen),\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "000820d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.5289\n",
      "Epoch 00001: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 15s 168ms/step - loss: 1.0048 - accuracy: 0.5289 - val_loss: 445.8049 - val_accuracy: 0.4521\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.8422 - accuracy: 0.5062\n",
      "Epoch 00002: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 11s 121ms/step - loss: 0.8422 - accuracy: 0.5062 - val_loss: 28.8023 - val_accuracy: 0.4521\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.5210\n",
      "Epoch 00003: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 11s 124ms/step - loss: 0.7279 - accuracy: 0.5210 - val_loss: 1.3196 - val_accuracy: 0.4521\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.7239 - accuracy: 0.5040\n",
      "Epoch 00004: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 11s 124ms/step - loss: 0.7239 - accuracy: 0.5040 - val_loss: 0.7414 - val_accuracy: 0.5479\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.5289\n",
      "Epoch 00005: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 11s 124ms/step - loss: 0.7476 - accuracy: 0.5289 - val_loss: 20.9288 - val_accuracy: 0.5479\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.5198\n",
      "Epoch 00006: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 11s 120ms/step - loss: 0.7232 - accuracy: 0.5198 - val_loss: 0.6928 - val_accuracy: 0.5479\n",
      "Epoch 7/10\n",
      "59/89 [==================>...........] - ETA: 3s - loss: 0.7030 - accuracy: 0.4940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c35fa4e6aafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_data_gen,\n",
    "        epochs = args.epochs,\n",
    "        steps_per_epoch = len(train_data_gen),        \n",
    "        validation_data = val_data_gen,\n",
    "        verbose = 1,\n",
    "        validation_steps = len(val_data_gen),\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "462063f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 2/89 [..............................] - ETA: 5s - loss: 5.3017 - accuracy: 0.5500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0402s vs `on_train_batch_end` time: 0.0823s). Check your callbacks.\n",
      "89/89 [==============================] - ETA: 0s - loss: 1.0513 - accuracy: 0.6059\n",
      "Epoch 00001: val_accuracy improved from 0.54795 to 0.63470, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.1-0.6347.hdf5\n",
      "89/89 [==============================] - 12s 133ms/step - loss: 1.0513 - accuracy: 0.6059 - val_loss: 0.6536 - val_accuracy: 0.6347\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.5819 - accuracy: 0.7305\n",
      "Epoch 00002: val_accuracy did not improve from 0.63470\n",
      "89/89 [==============================] - 11s 120ms/step - loss: 0.5819 - accuracy: 0.7305 - val_loss: 0.6673 - val_accuracy: 0.5982\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.7667\n",
      "Epoch 00003: val_accuracy improved from 0.63470 to 0.65753, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.3-0.6575.hdf5\n",
      "89/89 [==============================] - 11s 125ms/step - loss: 0.5006 - accuracy: 0.7667 - val_loss: 0.8318 - val_accuracy: 0.6575\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.8097\n",
      "Epoch 00004: val_accuracy improved from 0.65753 to 0.66210, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.4-0.6621.hdf5\n",
      "89/89 [==============================] - 11s 124ms/step - loss: 0.4613 - accuracy: 0.8097 - val_loss: 1.7336 - val_accuracy: 0.6621\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8301\n",
      "Epoch 00005: val_accuracy improved from 0.66210 to 0.70320, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.5-0.7032.hdf5\n",
      "89/89 [==============================] - 11s 126ms/step - loss: 0.3988 - accuracy: 0.8301 - val_loss: 0.9848 - val_accuracy: 0.7032\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8788\n",
      "Epoch 00006: val_accuracy did not improve from 0.70320\n",
      "89/89 [==============================] - 11s 120ms/step - loss: 0.3152 - accuracy: 0.8788 - val_loss: 1.6402 - val_accuracy: 0.6256\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.8901\n",
      "Epoch 00007: val_accuracy improved from 0.70320 to 0.74886, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.7-0.7489.hdf5\n",
      "89/89 [==============================] - 11s 125ms/step - loss: 0.2914 - accuracy: 0.8901 - val_loss: 0.6383 - val_accuracy: 0.7489\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.2802 - accuracy: 0.8890\n",
      "Epoch 00008: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 11s 119ms/step - loss: 0.2802 - accuracy: 0.8890 - val_loss: 0.8706 - val_accuracy: 0.6119\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.9026\n",
      "Epoch 00009: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 10s 118ms/step - loss: 0.2426 - accuracy: 0.9026 - val_loss: 3.0660 - val_accuracy: 0.6119\n",
      "Epoch 10/10\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.2670 - accuracy: 0.8989\n",
      "Epoch 00010: val_accuracy did not improve from 0.74886\n",
      "89/89 [==============================] - 10s 118ms/step - loss: 0.2665 - accuracy: 0.8992 - val_loss: 0.8232 - val_accuracy: 0.7169\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_data_gen,\n",
    "        epochs = args.epochs,\n",
    "        steps_per_epoch = len(train_data_gen),        \n",
    "        validation_data = val_data_gen,\n",
    "        verbose = 1,\n",
    "        validation_steps = len(val_data_gen),\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b42dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.7437 - accuracy: 0.5900\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61644, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.1-0.6164.hdf5\n",
      "89/89 [==============================] - 21s 238ms/step - loss: 0.7437 - accuracy: 0.5900 - val_loss: 0.6549 - val_accuracy: 0.6164\n",
      "Epoch 2/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.6852\n",
      "Epoch 00002: val_accuracy improved from 0.61644 to 0.68037, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.2-0.6804.hdf5\n",
      "89/89 [==============================] - 19s 214ms/step - loss: 0.6048 - accuracy: 0.6852 - val_loss: 0.5395 - val_accuracy: 0.6804\n",
      "Epoch 3/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.7463\n",
      "Epoch 00003: val_accuracy improved from 0.68037 to 0.72146, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.3-0.7215.hdf5\n",
      "89/89 [==============================] - 20s 221ms/step - loss: 0.5214 - accuracy: 0.7463 - val_loss: 0.6011 - val_accuracy: 0.7215\n",
      "Epoch 4/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8086\n",
      "Epoch 00004: val_accuracy did not improve from 0.72146\n",
      "89/89 [==============================] - 19s 210ms/step - loss: 0.4333 - accuracy: 0.8086 - val_loss: 0.6495 - val_accuracy: 0.6804\n",
      "Epoch 5/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.8279\n",
      "Epoch 00005: val_accuracy did not improve from 0.72146\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.4013 - accuracy: 0.8279 - val_loss: 0.6213 - val_accuracy: 0.7123\n",
      "Epoch 6/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8856\n",
      "Epoch 00006: val_accuracy did not improve from 0.72146\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.3047 - accuracy: 0.8856 - val_loss: 1.0409 - val_accuracy: 0.6621\n",
      "Epoch 7/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.8879\n",
      "Epoch 00007: val_accuracy did not improve from 0.72146\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.2705 - accuracy: 0.8879 - val_loss: 1.4931 - val_accuracy: 0.6941\n",
      "Epoch 8/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.9060\n",
      "Epoch 00008: val_accuracy did not improve from 0.72146\n",
      "89/89 [==============================] - 19s 210ms/step - loss: 0.2658 - accuracy: 0.9060 - val_loss: 1.1720 - val_accuracy: 0.6575\n",
      "Epoch 9/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9264\n",
      "Epoch 00009: val_accuracy improved from 0.72146 to 0.76256, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.9-0.7626.hdf5\n",
      "89/89 [==============================] - 19s 215ms/step - loss: 0.1881 - accuracy: 0.9264 - val_loss: 0.8653 - val_accuracy: 0.7626\n",
      "Epoch 10/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9354\n",
      "Epoch 00010: val_accuracy improved from 0.76256 to 0.76712, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.10-0.7671.hdf5\n",
      "89/89 [==============================] - 20s 226ms/step - loss: 0.1942 - accuracy: 0.9354 - val_loss: 0.9501 - val_accuracy: 0.7671\n",
      "Epoch 11/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9762\n",
      "Epoch 00011: val_accuracy did not improve from 0.76712\n",
      "89/89 [==============================] - 18s 206ms/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 1.3849 - val_accuracy: 0.6027\n",
      "Epoch 12/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9570\n",
      "Epoch 00012: val_accuracy did not improve from 0.76712\n",
      "89/89 [==============================] - 19s 209ms/step - loss: 0.1190 - accuracy: 0.9570 - val_loss: 0.6792 - val_accuracy: 0.7443\n",
      "Epoch 13/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9502\n",
      "Epoch 00013: val_accuracy did not improve from 0.76712\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.1272 - accuracy: 0.9502 - val_loss: 1.1490 - val_accuracy: 0.7306\n",
      "Epoch 14/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9445\n",
      "Epoch 00014: val_accuracy did not improve from 0.76712\n",
      "89/89 [==============================] - 18s 206ms/step - loss: 0.1448 - accuracy: 0.9445 - val_loss: 0.6984 - val_accuracy: 0.6804\n",
      "Epoch 15/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9366\n",
      "Epoch 00015: val_accuracy did not improve from 0.76712\n",
      "89/89 [==============================] - 19s 208ms/step - loss: 0.1623 - accuracy: 0.9366 - val_loss: 0.7144 - val_accuracy: 0.6895\n",
      "Epoch 16/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9672\n",
      "Epoch 00016: val_accuracy improved from 0.76712 to 0.78082, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.16-0.7808.hdf5\n",
      "89/89 [==============================] - 19s 214ms/step - loss: 0.1158 - accuracy: 0.9672 - val_loss: 1.0608 - val_accuracy: 0.7808\n",
      "Epoch 17/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9626\n",
      "Epoch 00017: val_accuracy did not improve from 0.78082\n",
      "89/89 [==============================] - 18s 206ms/step - loss: 0.1133 - accuracy: 0.9626 - val_loss: 1.0310 - val_accuracy: 0.7580\n",
      "Epoch 18/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9785\n",
      "Epoch 00018: val_accuracy did not improve from 0.78082\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.0800 - accuracy: 0.9785 - val_loss: 0.8612 - val_accuracy: 0.7260\n",
      "Epoch 19/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9751\n",
      "Epoch 00019: val_accuracy did not improve from 0.78082\n",
      "89/89 [==============================] - 19s 208ms/step - loss: 0.0775 - accuracy: 0.9751 - val_loss: 1.1744 - val_accuracy: 0.7671\n",
      "Epoch 20/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9762\n",
      "Epoch 00020: val_accuracy did not improve from 0.78082\n",
      "89/89 [==============================] - 19s 208ms/step - loss: 0.0736 - accuracy: 0.9762 - val_loss: 1.0592 - val_accuracy: 0.7260\n",
      "Epoch 21/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9955\n",
      "Epoch 00021: val_accuracy did not improve from 0.78082\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.9117 - val_accuracy: 0.7717\n",
      "Epoch 22/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9819\n",
      "Epoch 00022: val_accuracy improved from 0.78082 to 0.78995, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.22-0.7900.hdf5\n",
      "89/89 [==============================] - 19s 216ms/step - loss: 0.0763 - accuracy: 0.9819 - val_loss: 0.7207 - val_accuracy: 0.7900\n",
      "Epoch 23/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9649\n",
      "Epoch 00023: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 19s 208ms/step - loss: 0.1194 - accuracy: 0.9649 - val_loss: 0.8438 - val_accuracy: 0.7626\n",
      "Epoch 24/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9932\n",
      "Epoch 00024: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 19s 208ms/step - loss: 0.0261 - accuracy: 0.9932 - val_loss: 1.3272 - val_accuracy: 0.7900\n",
      "Epoch 25/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9638\n",
      "Epoch 00025: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 19s 216ms/step - loss: 0.0907 - accuracy: 0.9638 - val_loss: 1.1167 - val_accuracy: 0.7215\n",
      "Epoch 26/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9830\n",
      "Epoch 00026: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 19s 216ms/step - loss: 0.0737 - accuracy: 0.9830 - val_loss: 1.7088 - val_accuracy: 0.7215\n",
      "Epoch 27/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9932\n",
      "Epoch 00027: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 19s 215ms/step - loss: 0.0315 - accuracy: 0.9932 - val_loss: 1.0616 - val_accuracy: 0.7489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9864\n",
      "Epoch 00028: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 19s 212ms/step - loss: 0.0371 - accuracy: 0.9864 - val_loss: 1.0880 - val_accuracy: 0.7306\n",
      "Epoch 29/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9887\n",
      "Epoch 00029: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 20s 220ms/step - loss: 0.0417 - accuracy: 0.9887 - val_loss: 0.9293 - val_accuracy: 0.7580\n",
      "Epoch 30/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 00030: val_accuracy did not improve from 0.78995\n",
      "89/89 [==============================] - 20s 220ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 1.2320 - val_accuracy: 0.7580\n",
      "Epoch 31/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy improved from 0.78995 to 0.79909, saving model to /workspaces/ecdl/experiments/efficientnet_round1/weights.31-0.7991.hdf5\n",
      "89/89 [==============================] - 21s 233ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1972 - val_accuracy: 0.7991\n",
      "Epoch 32/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9898\n",
      "Epoch 00032: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 219ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 2.7814 - val_accuracy: 0.6393\n",
      "Epoch 33/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9422\n",
      "Epoch 00033: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 220ms/step - loss: 0.1446 - accuracy: 0.9422 - val_loss: 2.7425 - val_accuracy: 0.5845\n",
      "Epoch 34/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9717\n",
      "Epoch 00034: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 225ms/step - loss: 0.0822 - accuracy: 0.9717 - val_loss: 0.8179 - val_accuracy: 0.7169\n",
      "Epoch 35/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9887\n",
      "Epoch 00035: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 226ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 1.6805 - val_accuracy: 0.6712\n",
      "Epoch 36/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9943\n",
      "Epoch 00036: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 228ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 1.3507 - val_accuracy: 0.6986\n",
      "Epoch 37/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9649\n",
      "Epoch 00037: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 227ms/step - loss: 0.0996 - accuracy: 0.9649 - val_loss: 1.0864 - val_accuracy: 0.7397\n",
      "Epoch 38/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9909\n",
      "Epoch 00038: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 225ms/step - loss: 0.0366 - accuracy: 0.9909 - val_loss: 1.1976 - val_accuracy: 0.7580\n",
      "Epoch 39/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9841\n",
      "Epoch 00039: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 229ms/step - loss: 0.0438 - accuracy: 0.9841 - val_loss: 0.9174 - val_accuracy: 0.7443\n",
      "Epoch 40/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9887\n",
      "Epoch 00040: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 227ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.9732 - val_accuracy: 0.7626\n",
      "Epoch 41/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9921\n",
      "Epoch 00041: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 229ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.9438 - val_accuracy: 0.7854\n",
      "Epoch 42/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9989\n",
      "Epoch 00042: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 228ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 1.3305 - val_accuracy: 0.7306\n",
      "Epoch 43/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 00043: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 223ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.2788 - val_accuracy: 0.7489\n",
      "Epoch 44/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00044: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 216ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2982 - val_accuracy: 0.7717\n",
      "Epoch 45/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9977\n",
      "Epoch 00045: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 216ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 1.4291 - val_accuracy: 0.7352\n",
      "Epoch 46/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9853\n",
      "Epoch 00046: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 219ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 1.0782 - val_accuracy: 0.7032\n",
      "Epoch 47/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9864\n",
      "Epoch 00047: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 221ms/step - loss: 0.0412 - accuracy: 0.9864 - val_loss: 1.4388 - val_accuracy: 0.6575\n",
      "Epoch 48/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9966\n",
      "Epoch 00048: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 226ms/step - loss: 0.0243 - accuracy: 0.9966 - val_loss: 1.4301 - val_accuracy: 0.6986\n",
      "Epoch 49/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9864\n",
      "Epoch 00049: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 220ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 2.5736 - val_accuracy: 0.6986\n",
      "Epoch 50/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9717\n",
      "Epoch 00050: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 224ms/step - loss: 0.0841 - accuracy: 0.9717 - val_loss: 1.1148 - val_accuracy: 0.6758\n",
      "Epoch 51/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9898\n",
      "Epoch 00051: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 219ms/step - loss: 0.0444 - accuracy: 0.9898 - val_loss: 2.0259 - val_accuracy: 0.6301\n",
      "Epoch 52/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9751\n",
      "Epoch 00052: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 20s 222ms/step - loss: 0.0850 - accuracy: 0.9751 - val_loss: 1.1266 - val_accuracy: 0.6210\n",
      "Epoch 53/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9796\n",
      "Epoch 00053: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.0614 - accuracy: 0.9796 - val_loss: 0.8828 - val_accuracy: 0.7534\n",
      "Epoch 54/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9898\n",
      "Epoch 00054: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 214ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 1.1645 - val_accuracy: 0.7123\n",
      "Epoch 55/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9932\n",
      "Epoch 00055: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.0263 - accuracy: 0.9932 - val_loss: 1.0536 - val_accuracy: 0.7215\n",
      "Epoch 56/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9932\n",
      "Epoch 00056: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 1.2775 - val_accuracy: 0.7215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9921\n",
      "Epoch 00057: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 1.5587 - val_accuracy: 0.7032\n",
      "Epoch 58/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9853\n",
      "Epoch 00058: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 1.0214 - val_accuracy: 0.7443\n",
      "Epoch 59/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9875\n",
      "Epoch 00059: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 215ms/step - loss: 0.0434 - accuracy: 0.9875 - val_loss: 1.0478 - val_accuracy: 0.7306\n",
      "Epoch 60/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9966\n",
      "Epoch 00060: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 216ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 1.1484 - val_accuracy: 0.6986\n",
      "Epoch 61/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00061: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1238 - val_accuracy: 0.7580\n",
      "Epoch 62/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9977\n",
      "Epoch 00062: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 18s 208ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 1.2947 - val_accuracy: 0.7397\n",
      "Epoch 63/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00063: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 208ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2449 - val_accuracy: 0.7854\n",
      "Epoch 64/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9932\n",
      "Epoch 00064: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 215ms/step - loss: 0.0300 - accuracy: 0.9932 - val_loss: 1.0994 - val_accuracy: 0.7352\n",
      "Epoch 65/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9830\n",
      "Epoch 00065: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 219ms/step - loss: 0.0567 - accuracy: 0.9830 - val_loss: 1.8300 - val_accuracy: 0.6941\n",
      "Epoch 66/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9943\n",
      "Epoch 00066: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 18s 205ms/step - loss: 0.0264 - accuracy: 0.9943 - val_loss: 1.3711 - val_accuracy: 0.7534\n",
      "Epoch 67/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9230\n",
      "Epoch 00067: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 18s 206ms/step - loss: 0.1962 - accuracy: 0.9230 - val_loss: 3.5547 - val_accuracy: 0.6164\n",
      "Epoch 68/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9343\n",
      "Epoch 00068: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.1511 - accuracy: 0.9343 - val_loss: 1.1233 - val_accuracy: 0.7443\n",
      "Epoch 69/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9841\n",
      "Epoch 00069: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.0577 - accuracy: 0.9841 - val_loss: 1.0275 - val_accuracy: 0.7626\n",
      "Epoch 70/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9853\n",
      "Epoch 00070: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 18s 206ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.7440 - val_accuracy: 0.7260\n",
      "Epoch 71/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9989\n",
      "Epoch 00071: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 18s 207ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.9784 - val_accuracy: 0.7763\n",
      "Epoch 72/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 00072: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 215ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 1.1530 - val_accuracy: 0.7534\n",
      "Epoch 73/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9943\n",
      "Epoch 00073: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 217ms/step - loss: 0.0249 - accuracy: 0.9943 - val_loss: 0.8276 - val_accuracy: 0.7900\n",
      "Epoch 74/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 00074: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 214ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 1.0657 - val_accuracy: 0.7671\n",
      "Epoch 75/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00075: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 214ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1207 - val_accuracy: 0.7671\n",
      "Epoch 76/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9989\n",
      "Epoch 00076: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 215ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 1.2370 - val_accuracy: 0.7534\n",
      "Epoch 77/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9898\n",
      "Epoch 00077: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 213ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 1.2040 - val_accuracy: 0.7352\n",
      "Epoch 78/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9921\n",
      "Epoch 00078: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 214ms/step - loss: 0.0280 - accuracy: 0.9921 - val_loss: 1.5533 - val_accuracy: 0.6667\n",
      "Epoch 79/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9909\n",
      "Epoch 00079: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 211ms/step - loss: 0.0217 - accuracy: 0.9909 - val_loss: 0.9709 - val_accuracy: 0.7443\n",
      "Epoch 80/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9921\n",
      "Epoch 00080: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 209ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 1.0340 - val_accuracy: 0.7717\n",
      "Epoch 81/1000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 00081: val_accuracy did not improve from 0.79909\n",
      "89/89 [==============================] - 19s 219ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.7489\n",
      "Epoch 00081: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_data_gen,\n",
    "        epochs = 1000,\n",
    "        steps_per_epoch = len(train_data_gen),        \n",
    "        validation_data = val_data_gen,\n",
    "        verbose = 1,\n",
    "        validation_steps = len(val_data_gen),\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c9c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
