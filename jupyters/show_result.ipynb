{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import ecdl\n",
    "\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myargs():\n",
    "    def __init__(self):\n",
    "        self.exp_id = 'efficientnetb1_round3'\n",
    "        self.test_data = 'first'\n",
    "        self.load_type = 'model'\n",
    "   \n",
    "\n",
    "args = myargs()\n",
    "\n",
    "\n",
    "base_exp_path = '../experiments'\n",
    "exp_path = os.path.join(base_exp_path, args.exp_id)\n",
    "args_path = os.path.join(exp_path, 'hyperparameters.json')\n",
    "with open(args_path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "model = tf.keras.models.load_model(exp_path)\n",
    "\n",
    "if args.load_type == 'weight':\n",
    "    best_metric = 0.0\n",
    "    chosen_index = 0\n",
    "    all_weights = glob.glob(os.path.join(exp_path,'*.hdf5'))\n",
    "    metric_list = [float(weight_file.split('-')[-1].split('.hdf5')[0]) for weight_file in all_weights]    \n",
    "    for index,metric_value in enumerate(metric_list):\n",
    "        if best_metric < metric_value:\n",
    "            best_metric = metric_value\n",
    "            chosen_index = index\n",
    "    model.load_weights(all_weights[chosen_index])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(\n",
    "        num_thresholds=200, curve='ROC', summation_method='interpolation', name=None,\n",
    "        dtype=None, thresholds=None, multi_label=False, label_weights=None)\n",
    "        ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Choosing the experiment model to load and test')\n",
    "# parser.add_argument('--exp_id', default='experiments/elbow_efficientnet_lr_1e-4_rot60_ws0.1_hs0.1_zr0.2_round1/weights.16-0.7626.hdf5',type=str,metavar='EXP_ID',help='name of the experiment')\n",
    "# parser.add_argument('--exp_id', default='experiments/extended_training/weights.25-0.8174.hdf5',type=str,metavar='EXP_ID',help='name of the experiment')\n",
    "parser.add_argument('--exp_id', default='efficientnetb0_round3',type=str,metavar='EXP_ID',help='name of the experiment')\n",
    "parser.add_argument('--test_data', default='first',type=str,metavar='EXP_ID',help='Testing Dataset Choice')\n",
    "parser.add_argument('--load_type', default='model',type=str,metavar='EXP_ID',help='Whether to load model or best weight based on validation result')\n",
    "args = parser.parse_args()\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best model\n",
    "# python scripts/write_results_csv.py --exp_id efficientnetb1_round3 --test_data eval_both --load_type weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
